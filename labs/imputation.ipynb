{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imputation Example\n",
      "---\n",
      "* What if we have missing values for some data column?\n",
      "* Not all classifiers/regressors work with missing values\n",
      "* Scikit-learn provides methods for *imputing* missing values into the data\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's load the data\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy.io.arff import loadarff\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "# printing options\n",
      "np.set_printoptions(precision=4)\n",
      "np.set_printoptions(suppress=True)\n",
      "\n",
      "def arfftosk(filename):\n",
      "    \"\"\"Function to convert a .arff file to sklearn-compatible format\n",
      "\n",
      "    Keyword arguments:\n",
      "    filename -- the name of the file\n",
      "    \"\"\"\n",
      "\n",
      "    data_raw, metadata_raw = loadarff(filename)\n",
      "    df = pd.DataFrame(data_raw)\n",
      "    # numpy notation for multiple columns, select everything but the last column \n",
      "    X_df = df.iloc[:,:-2]\n",
      "    # last column is the hypothesis\n",
      "    y_df = df.iloc[:,-1]\n",
      "    y_encoder = LabelEncoder()\n",
      "    X = X_df.values\n",
      "    y = y_encoder.fit_transform(y_df)\n",
      "\n",
      "    \n",
      "    return X,y,y_encoder\n",
      "\n",
      "X_train,y_train, y_encoder = arfftosk(\"diabetes_missing.arff\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Array contents\n",
      "===\n",
      "* Let's see what we have loaded\n",
      "* Notice how missing data are represented as \"nan\" values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check the first five elements\n",
      "# \"nan\" values are missing values\n",
      "X_train[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "array([[   6.   ,      nan,   72.   ,   35.   ,    0.   ,   33.6  ,\n",
        "           0.627],\n",
        "       [   1.   ,      nan,   66.   ,   29.   ,    0.   ,   26.6  ,\n",
        "           0.351],\n",
        "       [   8.   ,      nan,   64.   ,    0.   ,    0.   ,   23.3  ,\n",
        "           0.672],\n",
        "       [   1.   ,      nan,   66.   ,   23.   ,   94.   ,   28.1  ,\n",
        "           0.167],\n",
        "       [   0.   ,      nan,   40.   ,   35.   ,  168.   ,   43.1  ,\n",
        "           2.288]])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's check training data for sanity\n",
      "y_train[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "array([1, 0, 1, 0, 1])"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imputation\n",
      "===\n",
      "* The process of filling missing values in data is called imputation\n",
      "* We need to do this because not all classifiers can adapt/work with missing data\n",
      "* Let's transform the data - notice the use of fit_transform that both fits and transforms the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Imputation, replace every missing column with the mean\n",
      "from sklearn.preprocessing import Imputer\n",
      "imp = Imputer()\n",
      "X_train_imp = imp.fit_transform(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Verify that the imputed data is there\n",
      "X_train_imp[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[   6.    ,  121.7077,   72.    ,   35.    ,    0.    ,   33.6   ,\n",
        "           0.627 ],\n",
        "       [   1.    ,  121.7077,   66.    ,   29.    ,    0.    ,   26.6   ,\n",
        "           0.351 ],\n",
        "       [   8.    ,  121.7077,   64.    ,    0.    ,    0.    ,   23.3   ,\n",
        "           0.672 ],\n",
        "       [   1.    ,  121.7077,   66.    ,   23.    ,   94.    ,   28.1   ,\n",
        "           0.167 ],\n",
        "       [   0.    ,  121.7077,   40.    ,   35.    ,  168.    ,   43.1   ,\n",
        "           2.288 ]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training a regressor\n",
      "===\n",
      "* Now that we have corrected the data, we can use linear regression to train a linear function on the data\n",
      "* We can also use $r^2$ to calculate the \"goodness of fit\" on the traning set\n",
      "* Notice how we get a lower score when doing cross validation - why is that? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's train a linear model!\n",
      "from sklearn.linear_model import LinearRegression as lr\n",
      "clf = lr()\n",
      "clf.fit(X_train_imp,y_train)\n",
      "print \"Regression coefficients:\" + str(clf.coef_)\n",
      "print \"Regression intercept:\" + str(clf.intercept_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Regression coefficients:[ 0.0288  0.0059 -0.0018 -0.0008  0.      0.0149  0.1702]\n",
        "Regression intercept:-0.901354900119\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's see how it performs on train and CV data\n",
      "from sklearn.metrics import r2_score\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "y_pred = clf.predict(X_train_imp)\n",
      "print \"Training set r^2:%f\"%(r2_score(y_train,y_pred))\n",
      "print \"Mean CV r^2:%f\"%(cross_val_score(clf, X_train_imp,y_train,cv = 10).mean())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training set r^2:0.266770\n",
        "Mean CV r^2:0.220254\n"
       ]
      }
     ],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}