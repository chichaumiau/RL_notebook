{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:7c6f12e824583211f1674f1f74d65e6aae47e87fde2f18f9a1697a14b804f245"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "The Markov Decision Process\n",
      "---\n",
      "***\n",
      "* The primary abstraction we are going to work with is the Markov Decision Process (MDP). \n",
      "* MDPs capture the dynamics of a mini-world/universe/environment\n",
      "* An MDP is defined as a tuple $<S,A,T,R,\\gamma>$ where: \n",
      "    * $S$, $s \\in S$ is a set of states\n",
      "    * $A$, $a \\in A$ is a set of actions\n",
      "    * $R:S$, $R(s,a)$ is a function that maps states to rewards\n",
      "    * $T:S\\times S\\times A$, with $T(s'| s, a)$ being the probability of an agent landing from state $s$ to state $s'$ after taking $a$\n",
      "    * $\\gamma$ is a discount factor - the impact of time on rewards\n",
      "    \n",
      "* This lab is just a demo of some of the principles we talked in class, now with transition loops\n",
      "* Most of the cose is based on the book  Artificial Intelligence, Artificial Intelligence: A Modern Approach \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "class MDP:\n",
      "    \"\"\"A Markov Decision Process, defined by an initial state, transition model,\n",
      "    and reward function. We also keep track of a gamma value, for use by\n",
      "    algorithms. We also keep track of the possible states, terminal states, and\n",
      "    actions for each state. [page 615,AIM]\"\"\"\n",
      "\n",
      "    def __init__(self, init, actlist, terminals, gamma=.99):\n",
      "        update(self, init=init, actlist=actlist, terminals=terminals,\n",
      "               gamma=gamma, states=set(), reward={})\n",
      "\n",
      "    def R(self, state, action):\n",
      "        \"Return a numeric reward for this state.\"\n",
      "        return self.reward[state][action]\n",
      "\n",
      "    def T(state, action):\n",
      "        \"\"\"Transition model.  From a state and an action, return a list\n",
      "        of (result-state, probability) pairs.\"\"\"\n",
      "        abstract\n",
      "        \n",
      "    def sample(state, action):\n",
      "        \"\"\"Sample from state action. Returns a new state\"\"\"\n",
      "        abstract\n",
      "\n",
      "    def actions(self, state):\n",
      "        \"\"\"Set of actions that can be performed in this state.  By default, a\n",
      "        fixed list of actions, except for terminal states. Override this\n",
      "        method if you need to specialize by state.\"\"\"\n",
      "        if state in self.terminals:\n",
      "            return [None]\n",
      "        else:\n",
      "            return self.actlist"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GridMDP(MDP):\n",
      "    \"\"\"A two-dimensional grid MDP, as in [Figure 17.1].  All you have to do is\n",
      "    specify the grid as a list of lists of rewards; use None for an obstacle\n",
      "    (unreachable state).  Also, you should specify the terminal states.\n",
      "    An action is an (x, y) unit vector; e.g. (1, 0) means move east.\"\"\"\n",
      "    def __init__(self, grid, terminals, init=(0, 0), gamma=.9):\n",
      "        MDP.__init__(self, init, actlist=orientations,\n",
      "                     terminals=terminals, gamma=gamma)\n",
      "        update(self, grid=grid, rows=len(grid), cols=len(grid[0]))\n",
      "        for x in range(self.rows):\n",
      "            for y in range(self.cols):\n",
      "                self.reward[x, y] = grid[x][y]\n",
      "                if grid[x][y] is not None:\n",
      "                    self.states.add((x, y))\n",
      "        self.orig_grid = grid\n",
      "\n",
      "    def T(self, state, action):\n",
      "        if action == None:\n",
      "            return 0.0, state\n",
      "        else:\n",
      "            return 1.0, self.go(state, action)\n",
      "        \n",
      "    def R(self, state, action):\n",
      "        \"Return a numeric reward for this state/action pair.\"\n",
      "        p_state_next, state_next = self.T(state,action)\n",
      "        if(state_next == state):\n",
      "            return 0\n",
      "        return self.reward[state_next]\n",
      "\n",
      "    def go(self, state, direction):\n",
      "        \"Return the state that results from going in this direction.\"\n",
      "        state1 = vector_add(state, direction)\n",
      "        return if_(state1 in self.states, state1, state)\n",
      "\n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import *\n",
      "grid = [[-0.00, -0.00, -0.00, +1],\n",
      "        [-0.00, -0.00, -0.00, -1],\n",
      "        [-0.00, -0.00, -0.00, -0.00]]\n",
      "terminals = [(0, 3), (1, 3)]\n",
      "gmdp = GridMDP(grid,terminals=[])\n",
      "\n",
      "from visualisation import Visualiser\n",
      "vsl = Visualiser()\n",
      "plt = vsl.to_plt(grid, fig = \"grid.png\")\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAD3CAYAAACdI9ZeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCcAGPwHyApPz55CSh0AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f450d154a10>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "class PIAgent():\n",
      "    \"\"\" A policy iteration agent\n",
      "    \"\"\"\n",
      "    def __init__(self,mdp, k):\n",
      "        self.mdp = mdp\n",
      "        self.k = k\n",
      "    \n",
      "    \n",
      "    def policyIteration(self):\n",
      "        \"\"\" Solve an MDP by policy iteration [Fig. 17.7, AIM], \n",
      "            A\n",
      "        \"\"\"\n",
      "        mdp = self.mdp\n",
      "        k = self.k\n",
      "        V = dict([(s, 0) for s in mdp.states])\n",
      "        pi = dict([(s, random.choice(mdp.actions(s))) for s in mdp.states])\n",
      "        while True:\n",
      "            V1 = V.copy()\n",
      "            V1 = self.policyEvaluation(pi, V1, mdp, k)\n",
      "            unchanged = True\n",
      "            for s in mdp.states:   \n",
      "                a = argmax(mdp.actions(s), lambda a: Q_value(a,s,V1,mdp))\n",
      "                if a != pi[s]:\n",
      "                    pi[s] = a\n",
      "                    unchanged = False\n",
      "            if unchanged:\n",
      "                self.V = V1\n",
      "                self.pi = pi\n",
      "                return\n",
      "\n",
      "    def deterministicQLearning(self, iterations, initial_state):\n",
      "        \"Solving an MDP by value iteration.\"\n",
      "        mdp = self.mdp\n",
      "        \n",
      "        Q = {}\n",
      "        R, T, gamma = mdp.R, mdp.T, mdp.gamma\n",
      "        state = initial_state\n",
      "        for i in range(0,iterations):\n",
      "            action = random.choice(mdp.actions(state))\n",
      "            p_next_state, next_state = T(state,action)\n",
      "            state_action = (state,action)\n",
      "          \n",
      "            maxQ_next = self.__state_actions(Q,next_state).max()\n",
      "            \n",
      "            Q[state_action] = R(state,action) + gamma*maxQ_next\n",
      "            #print state, action, R(state,action),Q[state_action],maxQ_next\n",
      "            \n",
      "            state = next_state\n",
      "            \n",
      "        \n",
      "        # We don't need to calculate the value, it's just easier to presentation purposes\n",
      "        V = dict([(s, self.__state_actions(Q,s).max()) for s in mdp.states])\n",
      "        pi = dict([(s, mdp.actions(s)[self.__state_actions(Q,s).argmax()]) for s in mdp.states])\n",
      "        \n",
      "        self.V = V\n",
      "        self.pi = pi  \n",
      "        \n",
      "        \n",
      "    def QLearning(self, iterations, initial_state, learning_rate):\n",
      "        \"Solving an MDP by value iteration.\"\n",
      "        mdp = self.mdp\n",
      "        \n",
      "        Q = {}\n",
      "        R, T, gamma = mdp.R, mdp.T, mdp.gamma\n",
      "        state = initial_state\n",
      "        for i in range(0,iterations):\n",
      "            action = random.choice(mdp.actions(state))\n",
      "            p_next_state, next_state = T(state,action)\n",
      "            state_action = (state,action)\n",
      "          \n",
      "            maxQ_next = self.__state_actions(Q,next_state).max()\n",
      "            Q_sa = Q.get(state_action,0)\n",
      "            Q_sa += learning_rate*(R(state,action) + gamma*maxQ_next - Q.get(state_action,0))\n",
      "            Q[state_action] = Q_sa\n",
      "            #print state, action, R(state,action),Q[state_action],maxQ_next\n",
      "            \n",
      "            state = next_state\n",
      "            \n",
      "        \n",
      "        # We don't need to calculate the value, it's just easier to show\n",
      "        V = dict([(s, self.__state_actions(Q,s).max()) for s in mdp.states])\n",
      "        pi = dict([(s, mdp.actions(s)[self.__state_actions(Q,s).argmax()]) for s in mdp.states])\n",
      "        \n",
      "        self.V = V\n",
      "        self.pi = pi  \n",
      "        \n",
      "        \n",
      "        \n",
      "            \n",
      "    def __state_actions(self, Q, state):\n",
      "        mdp = self.mdp\n",
      "        state_actions = np.array([Q.get((state,a), 0) for a in mdp.actions(state)]) \n",
      "        #print state_actions\n",
      "        return state_actions\n",
      "    "
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Effort one, with deterministic Q-Learning\n",
      "gmdp = GridMDP(grid,terminals=[])\n",
      "pia = PIAgent(gmdp, 50)\n",
      "pia.deterministicQLearning(49, (0,0))\n",
      "values, policy  = pia.V, pia.pi\n",
      "#print values\n",
      "#print policy\n",
      "vsl = Visualiser()\n",
      "plt = vsl.to_plt_arrows(grid, values, policy, fig = \"grid_solved.png\" )\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAADyCAYAAAAvMlyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f450d1410d0>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Effort two, with (real) Q-Learning\n",
      "gmdp = GridMDP(grid,terminals=[])\n",
      "pia = PIAgent(gmdp, 50)\n",
      "pia.QLearning(40, (0,0), 0.1)\n",
      "values, policy  = pia.V, pia.pi\n",
      "#print values\n",
      "#print policy\n",
      "vsl = Visualiser()\n",
      "plt = vsl.to_plt_arrows(grid, values, policy, fig = \"grid_solved.png\" )\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAADyCAYAAAAvMlyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f450ce98ad0>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}